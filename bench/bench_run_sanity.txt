/Volumes/1TB SSD/mlx-proj/mlx-lm/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020
  warnings.warn(
Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 93902.33it/s]
[static_batch_generate] n=8 tokens=128 wall=0.36s tokens/s=355.66 ttft mean=359.9ms median=359.9ms p95=359.9ms
[INFO] tick wait=1 active=1 prefill_tokens=19 prefill_calls=1 prefill_ms=0.01 decode_batch=1 decode_iters=1 decode_tokens=1 decode_ms=116.60 generator_active=1 uid_map=1
Exception in thread mlx-lm-batcher:
Traceback (most recent call last):
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/Volumes/1TB SSD/mlx-proj/mlx-lm/mlx_lm/server_batched/runtime.py", line 54, in _worker_loop
    self.scheduler.step()
  File "/Volumes/1TB SSD/mlx-proj/mlx-lm/mlx_lm/server_batched/scheduler.py", line 90, in step
    decode_stats = self.runner.decode(active_snapshot)
  File "/Volumes/1TB SSD/mlx-proj/mlx-lm/mlx_lm/server_batched/engine.py", line 163, in decode
    responses = self.generator.next()
  File "/Volumes/1TB SSD/mlx-proj/mlx-lm/mlx_lm/generate.py", line 1050, in next
    return self._next()
  File "/Volumes/1TB SSD/mlx-proj/mlx-lm/mlx_lm/generate.py", line 1009, in _next
    batch.y, batch.logprobs = self._step(y[:, None], batch.cache)
  File "/Volumes/1TB SSD/mlx-proj/mlx-lm/mlx_lm/generate.py", line 959, in _step
    logits = self.model(input_tokens, cache=prompt_cache)
  File "/Volumes/1TB SSD/mlx-proj/mlx-lm/mlx_lm/models/llama.py", line 231, in __call__
    out = self.model(inputs, cache, input_embeddings)
  File "/Volumes/1TB SSD/mlx-proj/mlx-lm/mlx_lm/models/llama.py", line 211, in __call__
    h = layer(h, mask, cache=cache)
  File "/Volumes/1TB SSD/mlx-proj/mlx-lm/mlx_lm/models/llama.py", line 160, in __call__
    r = self.self_attn(self.input_layernorm(x), mask, cache)
  File "/Volumes/1TB SSD/mlx-proj/mlx-lm/mlx_lm/models/llama.py", line 108, in __call__
    keys, values = cache.update_and_fetch(keys, values)
  File "/Volumes/1TB SSD/mlx-proj/mlx-lm/mlx_lm/models/cache.py", line 711, in update_and_fetch
    self.keys[..., prev : self._idx, :] = keys
ValueError: [broadcast_shapes] Shapes (2,8,1,128) and (3,8,1,128) cannot be broadcast.
